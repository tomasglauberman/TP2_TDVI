{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, space_eval\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables\n",
    "\n",
    "\n",
    "accepts_mercadopago Whether the item accepts Mercado Pago. Todas aceptan, la saco\n",
    "available_quantity The available stock quantity at that moment\n",
    "avg_gmv_item_domain_30days Average revenue generated by the items of this domain on the last month\n",
    "avg_gmv_item_sel Average revenue of items of this seller\n",
    "avg_gmv_seller_bday Average revenue this seller makes by day\n",
    "avg_qty_orders_item_domain_30days Average number of orders a random item of this domain made on the last month\n",
    "avg_qty_orders_item_sel_30days Average number of orders an item of this seller makes on the last 30 days\n",
    "avg_si_item_sel_30day Average units sold of an item of this seller on the past month\n",
    "benefit Ignore, should be dropped\n",
    "boosted Whether the item was boosted\n",
    "category_id Category of this item\n",
    "conversion Target variable, it is True if this print has an attributed order\n",
    "date Print date\n",
    "deal_print_id Unique id for the print\n",
    "domain_id Domain id for the item\n",
    "etl_version Ignore, should be dropped\n",
    "free_shipping Whether the item has free shipping\n",
    "fulfillment Whether the item is fulfilled by MeLi\n",
    "full_name Category full name\n",
    "health Item health\n",
    "is_pdp Whether the click landed on a PDP\n",
    "product_id Product_id of the item\n",
    "item_id ID of the item, useful for debugging\n",
    "listing_type_id Whether the item is gold or not\n",
    "logistic_type Logistic type for the item\n",
    "main_picture URL for the main item picture\n",
    "offset On which page the item was rendered\n",
    "original_price Price from which the discount was done\n",
    "platform Which platform the user is using\n",
    "price Item price\n",
    "print_position Position on the page\n",
    "print_server_timestamp Timestamp for the print\n",
    "qty_items_dom Number of items this domain has\n",
    "qty_items_sel Number of items the seller has\n",
    "rn Leftover from the ETL, Discard\n",
    "ROW_ID Row of the submission file\n",
    "site_id Site ID\n",
    "sold_quantity Number of items sold at the moment of the print\n",
    "tags Tags the item had at the moment of the print\n",
    "title Item title\n",
    "total_asp_item_domain_30days Average selling price of the items of the domain\n",
    "total_asp_item_sel_30days Average selling price of all the items the seller sold on the last 30 days\n",
    "total_gmv_domain_bday total_gmv_domain_30days / 30       Total revenue the domain made on the last 30 days\n",
    "total_gmv_item_30days Total revenue made by the item on the lasts 30 days\n",
    "total_items_domain Number of items on the domain\n",
    "total_items_seller Number of items the seller has\n",
    "total_orders_domain_30days Total orders on the domain\n",
    "total_orders_item_30days Total orders the Item had on the last 30 days\n",
    "total_orders_sel_30days Total orders for the seller\n",
    "total_si_domain_30days Total units sold of this domain\n",
    "total_si_item_30days Total units sold of this item\n",
    "total_si_sel_30days Same for the seller\n",
    "total_visits_domain Total visits on this domain\n",
    "total_visits_item Total visits this item had\n",
    "total_visits_seller Total visits for this seller\n",
    "uid session id\n",
    "user_id user id\n",
    "warranty Whether the item had warranty\n",
    "conversion should be predicted for those rows where ROW_ID is not missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/competition_data.csv\")\n",
    "data.drop(columns=['benefit', 'category_id', 'deal_print_id','etl_version', 'full_name','product_id'\n",
    "                   , 'item_id', 'main_picture', 'site_id', 'uid', 'user_id', 'title', 'tags', 'warranty'],\n",
    "                     axis= \"columns\", inplace=True)\n",
    "\n",
    "data['conversion'] = data['conversion'].astype('bool')\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data[\"hour\"] = data[\"date\"].dt.hour\n",
    "data[\"day\"] = data[\"date\"].dt.day\n",
    "#data[\"minute\"] = data[\"date\"].dt.minute\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data.drop(columns=[\"print_server_timestamp\", 'date', \"domain_id\"], axis= \"columns\", inplace=True)\n",
    "data = pd.get_dummies(data,columns = [\"listing_type_id\", \"logistic_type\", \"platform\"],dummy_na = False, dtype = int)\n",
    "data = pd.get_dummies(data,columns = [\"is_pdp\"],dummy_na = True, dtype = bool )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data[\"ROW_ID\"].isna()]\n",
    "test_data = data[data[\"ROW_ID\"].notna()]\n",
    "\n",
    "x_train = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "y_train = train_data[\"conversion\"]\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=3456)\n",
    "X_test = test_data.drop(columns=[\"conversion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search space for hyperopt HistGradientBoostingClassifier()\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    'max_iter': hp.choice('max_iter', np.arange(100, 500, 10, dtype=int)),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', np.arange(10, 100, 10, dtype=int)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(10, 100, 10, dtype=int)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 10, 1, dtype=int)),\n",
    "    'l2_regularization': hp.uniform('l2_regularization', 0.01, 0.5),\n",
    "    'max_bins': hp.choice('max_bins', np.arange(10, 100, 10, dtype=int)),\n",
    "    'validation_fraction': hp.uniform('validation_fraction', 0.01, 0.5),\n",
    "    'n_iter_no_change': hp.choice('n_iter_no_change', np.arange(1, 10, 1, dtype=int)),\n",
    "    #'tol': hp.uniform('tol', 0.0001, 0.001),\n",
    "    #'scoring': hp.choice('scoring', ['loss', 'accuracy', 'balanced_accuracy', 'average_precision', 'f1', 'f1_micro', 'f1_macro', 'f1_weighted', 'f1_samples', 'neg_log_loss', 'precision', 'recall', 'roc_auc']),\n",
    "    #'random_state': hp.choice('random_state', np.arange(1, 100, 1, dtype=int)),\n",
    "    'warm_start': hp.choice('warm_start', [True, False]),\n",
    "    'early_stopping': hp.choice('early_stopping', [True, False]),\n",
    "    #'verbose': hp.choice('verbose', [True, False])\n",
    "\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    tree = HistGradientBoostingClassifier(**params, random_state = 22, scoring=\"roc_auc\")\n",
    "    score = cross_val_score(tree, x_train, y_train, cv = KFold(4)).mean() # Aplicamos validación cruzada con 4 folds.\n",
    "    return {'loss': 1 - score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:58<00:00, 19.42s/trial, best loss: 0.0887580864576425] \n"
     ]
    }
   ],
   "source": [
    "best = fmin(objective, space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 5,\n",
    "            rstate = np.random.default_rng(22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS:  {'early_stopping': False, 'l2_regularization': 0.35979456172848456, 'learning_rate': 0.035719415867667643, 'max_bins': 10, 'max_depth': 60, 'max_iter': 260, 'max_leaf_nodes': 60, 'min_samples_leaf': 9, 'n_iter_no_change': 4, 'validation_fraction': 0.4578017029077751, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(\"BEST PARAMS: \", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9110170663568722\n",
      "0.8925772210844479\n"
     ]
    }
   ],
   "source": [
    "hist_gradient = HistGradientBoostingClassifier(**best_params,scoring=\"roc_auc\")\n",
    "hist_gradient.fit(X_train, Y_train)\n",
    "print(hist_gradient.score(X_val, Y_val))\n",
    "print(roc_auc_score(Y_val, hist_gradient.predict_proba(X_val)[:, hist_gradient.classes_== 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88701696 0.88943346 0.88824374 0.88596927 0.88562665]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "scores = cross_val_score(hist_gradient, x_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = hist_gradient.predict_proba(X_test.drop(columns=[\"ROW_ID\"]))[:, hist_gradient.classes_== 1].squeeze()\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": X_test[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"./outputs/hist_gradient2.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
