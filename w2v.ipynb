{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Processing and metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "# Optimization\n",
    "from scipy.stats import uniform, loguniform\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# NLP\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/competition_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos\n",
    "Se realiza una selección de variables por filtering. Luego se realizan las conversiones de datos necesarias. \n",
    "\n",
    "TODO:\n",
    "- full_name\n",
    "- tags\n",
    "- title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['benefit', 'deal_print_id','etl_version', 'full_name', 'tags',\n",
    "                   'item_id', 'main_picture', 'product_id', 'date',\n",
    "                   'site_id','uid', 'user_id', 'category_id', 'domain_id'], axis= \"columns\", inplace=True)\n",
    "\n",
    "data['warranty'] = data['warranty'] != 'Sin garantía'\n",
    "data['conversion'] = data['conversion'].astype('bool')\n",
    "data[\"print_server_timestamp\"] = pd.to_datetime(data[\"print_server_timestamp\"])\n",
    "data[\"hour\"] = data[\"print_server_timestamp\"].dt.hour\n",
    "data[\"day\"] = data[\"print_server_timestamp\"].dt.day\n",
    "data[\"month\"] = data[\"print_server_timestamp\"].dt.month\n",
    "data.drop(columns=[\"print_server_timestamp\"], axis= \"columns\", inplace=True)\n",
    "data = pd.get_dummies(data,columns = [\"listing_type_id\", \"logistic_type\", \"platform\"], dummy_na = False, dtype = int)\n",
    "data = pd.get_dummies(data, columns = [\"is_pdp\"], dummy_na = True, dtype = int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento de columna 'title' con w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(raw_text):\n",
    "    \"\"\"\n",
    "    Tokeniza y preprocesa un texto.\n",
    "\n",
    "    Args:\n",
    "        raw_text (str): Texto sin procesar.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de oraciones, donde cada oración es una lista de palabras.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(raw_text)\n",
    "    sentences = [word_tokenize(e) for e in sentences]\n",
    "    sentences = [[e2 for e2 in e1 if re.compile(\"[A-Za-z]\").search(e2[0])] for e1 in sentences]\n",
    "    sentences = [[e2.lower() for e2 in e1] for e1 in sentences]\n",
    "    return(sentences)\n",
    "\n",
    "def average_vectors(title_tokens, model, stopwords=None):\n",
    "    \"\"\"\n",
    "    Calcula el vector promedio de un conjunto de tokens utilizando un modelo Word2Vec.\n",
    "\n",
    "    Args:\n",
    "        title_tokens (list): Lista de tokens.\n",
    "        model (gensim.models.Word2Vec): Modelo Word2Vec.\n",
    "        stopwords (set, optional): Conjunto de palabras stopwords. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Vector promedio.\n",
    "    \"\"\"\n",
    "    title_tokens = [e2 for e1 in title_tokens for e2 in e1]\n",
    "    title_tokens = [e for e in title_tokens if e in model.wv]\n",
    "    if stopwords is not None:\n",
    "        title_tokens = [e for e in title_tokens if e not in stopwords]\n",
    "    if len(title_tokens) == 0:\n",
    "        output = np.zeros(model.wv.vector_size)\n",
    "    else:\n",
    "        output = np.array([model.wv.get_vector(e) for e in title_tokens]).mean(0)\n",
    "    return output\n",
    "\n",
    "def PCA_K1(dataframe):\n",
    "    scaler = StandardScaler(with_std=True, with_mean=True)\n",
    "    pca = PCA()\n",
    "    pca.fit(scaler.fit_transform(dataframe))\n",
    "    return pca\n",
    "\n",
    "def PCA_TRANSFORM(title_tokens, pca):\n",
    "    return pca.transform(title_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74029810, 74992250)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_WORDS_SP = set(stopwords.words('spanish'))\n",
    "\n",
    "data[\"title_tokens\"] = data[\"title\"].map(tokenizer)\n",
    "\n",
    "# Creación del modelo Word2Vec\n",
    "w2v_tp = gensim.models.Word2Vec(vector_size=150,\n",
    "                                window=3,\n",
    "                                min_count=5,\n",
    "                                negative=10,\n",
    "                                sample=0.01,\n",
    "                                workers=8,\n",
    "                                sg=1)\n",
    "\n",
    "# Creación del vocabulario a partir del corpus\n",
    "w2v_tp.build_vocab([e2 for e1 in data[\"title_tokens\"].values for e2 in e1],\n",
    "                   progress_per=10000)\n",
    "\n",
    "# Entrenamiento del modelo Word2Vec\n",
    "w2v_tp.train([e2 for e1 in data[\"title_tokens\"].values for e2 in e1],\n",
    "             total_examples=w2v_tp.corpus_count,\n",
    "             epochs=50, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embs = data[\"title_tokens\"].map(lambda x: average_vectors(x, w2v_tp, STOP_WORDS_SP))\n",
    "title_embs = np.array(title_embs.to_list())\n",
    "data = pd.concat([data, pd.DataFrame(title_embs)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"title\", \"title_tokens\"], axis= \"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data[\"ROW_ID\"].isna()]\n",
    "test_data = data[data[\"ROW_ID\"].notna()]\n",
    "\n",
    "x_train = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "y_train = train_data[\"conversion\"]\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=3456)\n",
    "X_test = test_data.drop(columns=[\"conversion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bylevel': 0.8219490559795931, 'colsample_bynode': 0.24759470484372925, 'colsample_bytree': 0.7182253566785832, 'eta': 0.10879724556393319, 'gamma': 0.013905544512424909, 'max_depth': 7, 'min_child_weight': 9.0, 'n_estimators': 160, 'scale_pos_weight': 1, 'subsample': 0.7282346960910877}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86347\n",
      "[1]\tvalidation_0-auc:0.87033\n",
      "[2]\tvalidation_0-auc:0.86600\n",
      "[3]\tvalidation_0-auc:0.85524\n",
      "[4]\tvalidation_0-auc:0.86675\n",
      "[5]\tvalidation_0-auc:0.87244\n",
      "[6]\tvalidation_0-auc:0.87506\n",
      "[7]\tvalidation_0-auc:0.87595\n",
      "[8]\tvalidation_0-auc:0.87764\n",
      "[9]\tvalidation_0-auc:0.87804\n",
      "[10]\tvalidation_0-auc:0.87887\n",
      "[11]\tvalidation_0-auc:0.87936\n",
      "[12]\tvalidation_0-auc:0.88010\n",
      "[13]\tvalidation_0-auc:0.88011\n",
      "[14]\tvalidation_0-auc:0.88036\n",
      "[15]\tvalidation_0-auc:0.88112\n",
      "[16]\tvalidation_0-auc:0.88139\n",
      "[17]\tvalidation_0-auc:0.88158\n",
      "[18]\tvalidation_0-auc:0.88184\n",
      "[19]\tvalidation_0-auc:0.88211\n",
      "[20]\tvalidation_0-auc:0.88238\n",
      "[21]\tvalidation_0-auc:0.88234\n",
      "[22]\tvalidation_0-auc:0.88263\n",
      "[23]\tvalidation_0-auc:0.88279\n",
      "[24]\tvalidation_0-auc:0.88289\n",
      "[25]\tvalidation_0-auc:0.88320\n",
      "[26]\tvalidation_0-auc:0.88352\n",
      "[27]\tvalidation_0-auc:0.88364\n",
      "[28]\tvalidation_0-auc:0.88378\n",
      "[29]\tvalidation_0-auc:0.88433\n",
      "[30]\tvalidation_0-auc:0.88484\n",
      "[31]\tvalidation_0-auc:0.88497\n",
      "[32]\tvalidation_0-auc:0.88508\n",
      "[33]\tvalidation_0-auc:0.88521\n",
      "[34]\tvalidation_0-auc:0.88532\n",
      "[35]\tvalidation_0-auc:0.88567\n",
      "[36]\tvalidation_0-auc:0.88601\n",
      "[37]\tvalidation_0-auc:0.88631\n",
      "[38]\tvalidation_0-auc:0.88640\n",
      "[39]\tvalidation_0-auc:0.88664\n",
      "[40]\tvalidation_0-auc:0.88674\n",
      "[41]\tvalidation_0-auc:0.88693\n",
      "[42]\tvalidation_0-auc:0.88731\n",
      "[43]\tvalidation_0-auc:0.88741\n",
      "[44]\tvalidation_0-auc:0.88772\n",
      "[45]\tvalidation_0-auc:0.88780\n",
      "[46]\tvalidation_0-auc:0.88812\n",
      "[47]\tvalidation_0-auc:0.88823\n",
      "[48]\tvalidation_0-auc:0.88849\n",
      "[49]\tvalidation_0-auc:0.88851\n",
      "[50]\tvalidation_0-auc:0.88867\n",
      "[51]\tvalidation_0-auc:0.88888\n",
      "[52]\tvalidation_0-auc:0.88893\n",
      "[53]\tvalidation_0-auc:0.88902\n",
      "[54]\tvalidation_0-auc:0.88929\n",
      "[55]\tvalidation_0-auc:0.88942\n",
      "[56]\tvalidation_0-auc:0.88950\n",
      "[57]\tvalidation_0-auc:0.88969\n",
      "[58]\tvalidation_0-auc:0.88985\n",
      "[59]\tvalidation_0-auc:0.88996\n",
      "[60]\tvalidation_0-auc:0.89008\n",
      "[61]\tvalidation_0-auc:0.89002\n",
      "[62]\tvalidation_0-auc:0.89004\n",
      "[63]\tvalidation_0-auc:0.89015\n",
      "[64]\tvalidation_0-auc:0.89048\n",
      "[65]\tvalidation_0-auc:0.89049\n",
      "[66]\tvalidation_0-auc:0.89076\n",
      "[67]\tvalidation_0-auc:0.89081\n",
      "[68]\tvalidation_0-auc:0.89093\n",
      "[69]\tvalidation_0-auc:0.89112\n",
      "[70]\tvalidation_0-auc:0.89122\n",
      "[71]\tvalidation_0-auc:0.89133\n",
      "[72]\tvalidation_0-auc:0.89141\n",
      "[73]\tvalidation_0-auc:0.89164\n",
      "[74]\tvalidation_0-auc:0.89164\n",
      "[75]\tvalidation_0-auc:0.89175\n",
      "[76]\tvalidation_0-auc:0.89187\n",
      "[77]\tvalidation_0-auc:0.89184\n",
      "[78]\tvalidation_0-auc:0.89195\n",
      "[79]\tvalidation_0-auc:0.89211\n",
      "[80]\tvalidation_0-auc:0.89223\n",
      "[81]\tvalidation_0-auc:0.89230\n",
      "[82]\tvalidation_0-auc:0.89231\n",
      "[83]\tvalidation_0-auc:0.89234\n",
      "[84]\tvalidation_0-auc:0.89246\n",
      "[85]\tvalidation_0-auc:0.89242\n",
      "[86]\tvalidation_0-auc:0.89253\n",
      "[87]\tvalidation_0-auc:0.89260\n",
      "[88]\tvalidation_0-auc:0.89270\n",
      "[89]\tvalidation_0-auc:0.89278\n",
      "[90]\tvalidation_0-auc:0.89283\n",
      "[91]\tvalidation_0-auc:0.89283\n",
      "[92]\tvalidation_0-auc:0.89290\n",
      "[93]\tvalidation_0-auc:0.89284\n",
      "[94]\tvalidation_0-auc:0.89299\n",
      "[95]\tvalidation_0-auc:0.89307\n",
      "[96]\tvalidation_0-auc:0.89304\n",
      "[97]\tvalidation_0-auc:0.89306\n",
      "[98]\tvalidation_0-auc:0.89304\n",
      "[99]\tvalidation_0-auc:0.89310\n",
      "[100]\tvalidation_0-auc:0.89320\n",
      "[101]\tvalidation_0-auc:0.89329\n",
      "[102]\tvalidation_0-auc:0.89336\n",
      "[103]\tvalidation_0-auc:0.89349\n",
      "[104]\tvalidation_0-auc:0.89353\n",
      "[105]\tvalidation_0-auc:0.89357\n",
      "[106]\tvalidation_0-auc:0.89362\n",
      "[107]\tvalidation_0-auc:0.89364\n",
      "[108]\tvalidation_0-auc:0.89376\n",
      "[109]\tvalidation_0-auc:0.89388\n",
      "[110]\tvalidation_0-auc:0.89386\n",
      "[111]\tvalidation_0-auc:0.89395\n",
      "[112]\tvalidation_0-auc:0.89402\n",
      "[113]\tvalidation_0-auc:0.89409\n",
      "[114]\tvalidation_0-auc:0.89412\n",
      "[115]\tvalidation_0-auc:0.89421\n",
      "[116]\tvalidation_0-auc:0.89421\n",
      "[117]\tvalidation_0-auc:0.89423\n",
      "[118]\tvalidation_0-auc:0.89425\n",
      "[119]\tvalidation_0-auc:0.89423\n",
      "[120]\tvalidation_0-auc:0.89426\n",
      "[121]\tvalidation_0-auc:0.89431\n",
      "[122]\tvalidation_0-auc:0.89433\n",
      "[123]\tvalidation_0-auc:0.89436\n",
      "[124]\tvalidation_0-auc:0.89433\n",
      "[125]\tvalidation_0-auc:0.89436\n",
      "[126]\tvalidation_0-auc:0.89444\n",
      "[127]\tvalidation_0-auc:0.89454\n",
      "[128]\tvalidation_0-auc:0.89459\n",
      "[129]\tvalidation_0-auc:0.89457\n",
      "[130]\tvalidation_0-auc:0.89459\n",
      "[131]\tvalidation_0-auc:0.89461\n",
      "[132]\tvalidation_0-auc:0.89468\n",
      "[133]\tvalidation_0-auc:0.89471\n",
      "[134]\tvalidation_0-auc:0.89479\n",
      "[135]\tvalidation_0-auc:0.89484\n",
      "[136]\tvalidation_0-auc:0.89485\n",
      "[137]\tvalidation_0-auc:0.89488\n",
      "[138]\tvalidation_0-auc:0.89489\n",
      "[139]\tvalidation_0-auc:0.89495\n",
      "[140]\tvalidation_0-auc:0.89502\n",
      "[141]\tvalidation_0-auc:0.89502\n",
      "[142]\tvalidation_0-auc:0.89502\n",
      "[143]\tvalidation_0-auc:0.89511\n",
      "[144]\tvalidation_0-auc:0.89514\n",
      "[145]\tvalidation_0-auc:0.89523\n",
      "[146]\tvalidation_0-auc:0.89520\n",
      "[147]\tvalidation_0-auc:0.89523\n",
      "[148]\tvalidation_0-auc:0.89525\n",
      "[149]\tvalidation_0-auc:0.89525\n",
      "[150]\tvalidation_0-auc:0.89522\n",
      "[151]\tvalidation_0-auc:0.89522\n",
      "[152]\tvalidation_0-auc:0.89519\n",
      "[153]\tvalidation_0-auc:0.89521\n",
      "[154]\tvalidation_0-auc:0.89515\n",
      "[155]\tvalidation_0-auc:0.89522\n",
      "[156]\tvalidation_0-auc:0.89525\n",
      "[157]\tvalidation_0-auc:0.89530\n",
      "[158]\tvalidation_0-auc:0.89531\n",
      "[159]\tvalidation_0-auc:0.89533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=0.8219490559795931,\n",
       "              colsample_bynode=0.24759470484372925,\n",
       "              colsample_bytree=0.7182253566785832, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.10879724556393319,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0.013905544512424909,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=9.0, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=160, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=0.8219490559795931,\n",
       "              colsample_bynode=0.24759470484372925,\n",
       "              colsample_bytree=0.7182253566785832, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.10879724556393319,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0.013905544512424909,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=9.0, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=160, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=0.8219490559795931,\n",
       "              colsample_bynode=0.24759470484372925,\n",
       "              colsample_bytree=0.7182253566785832, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.10879724556393319,\n",
       "              eval_metric='auc', feature_types=None, gamma=0.013905544512424909,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=9.0, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=160, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    seed = 100,\n",
    "    eval_metric = 'auc',\n",
    "    **params)\n",
    "clf.fit(X_train, Y_train, verbose = True, eval_set = [(X_val, Y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict_proba(X_test.drop(columns=[\"ROW_ID\"]))[:, clf.classes_== 1].squeeze()\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": X_test[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"./outputs/w2v.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          feature  importance\n",
      "0                      is_pdp_nan    0.311375\n",
      "1                    is_pdp_False    0.247014\n",
      "2                          offset    0.028327\n",
      "3           platform_/web/desktop    0.022255\n",
      "4                     is_pdp_True    0.018905\n",
      "..                            ...         ...\n",
      "149                       boosted    0.000000\n",
      "150     logistic_type_xd_drop_off    0.000000\n",
      "151         logistic_type_default    0.000000\n",
      "152  listing_type_id_gold_special    0.000000\n",
      "153           accepts_mercadopago    0.000000\n",
      "\n",
      "[154 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({'feature': X_train.columns, 'importance': clf.feature_importances_})\n",
    "feature_importance.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importance.reset_index(drop=True, inplace=True)\n",
    "print(feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metodos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
